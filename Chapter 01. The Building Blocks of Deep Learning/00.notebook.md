# 1. The deep neural network architectures
* Một mạng có thể có 100 neuron hay thậm chí hàng triệu neuron.

## 1.1. Neurons
* Neuron là một đơn vị trong một neural network.
* Các neuron sẽ sắp xếp thành các layer.
* Chúng ta dùng kí hiệu $n_k^l$ trong đó $l$ là layer mà neuron này thuộc về và $k$ là số lượng neuron nằm trong cùng layer với neuron này.
* Các neuron có hai chức năng chính và chúng làm việc cùng nhau, bao gồm:
  * ***A linear function*** [một hàm tuyến tính].
  * ***Activation function*** [hàm kích hoạt].

### 1.1.1. The neuron linear function
* Output của một linear function là **tổng của các đầu vào** - với mỗi đầu vào được nhân cho một ***coefficient*** [hệ số] tương ứng.
* Các coefficient còn được gọi là ***weights*** [các trọng số] của neural network.
* Ví dụ, cho một neuron với input lần lượt là $x_1, x_2, x_3$ và output là $z$, lúc này linear function của neuron là:
  $$z = x_1\theta_1 + x_2\theta_2 + x_3\theta_3 + b \tag{1.1.1.1}$$
  * Với $\{\theta_1, \theta_2, \theta_3\}$ là weights (hoặc coefficients) mà chúng ta cần tìm và $b$ được gọi là **bias**.

### 1.1.2. Neuron activation functions
* Dưới đây ta có activation function $sigmoid$, định nghĩa như sau:
  * Công thức:
  
    $$sigmoid(z) = \dfrac{1}{1 + e^{-z}} \tag{1.1.2.1}$$

  * Giá trị của hàm $sigmoid(z) \in (0, 1)$.
    <center>
    
      ![](images/01.00.png) 

      _Hình 1.1.2.1_
  
    </center>

* Một activation function khác là $tanh$, định nghĩa như sau:
  * Công thức:
  
    $$tanh(z) = \dfrac{e^z - e^{-z}}{e^z + e^{-z}} \tag{1.1.2.2}$$

  * Giá trị của hàm $tanh(z) \in (-1, 1)$.
    <center>

      ![](images/01.01.png)

      _Hình 1.1.2.2_

    </center>

  * Hàm $tanh$ thường được ưa dùng hơn $sigmoid$ vì nó khắc phục được một hiện tượng là ***vanishing/exploding gradient*** [gradient biến mất/bùng nổ] - vanishing gradient khiến cho network hội tụ chậm và với $tanh$, network có xu hướng hội tụ nhanh hơn là so với $sigmoid$ _(tìm hiểu sau)_, tuy nhiêm vẫn không nhanh bằng $ReLu$.

* Activation function $ReLu$, định nghĩa như sau:
  * Công thức:
    $$f(z) = \max{(0, z)} \tag{1.1.2.3}$$

    <center>

      ![](images/01.02.png)

      _Hình 1.1.2.3_

    </center>

  * $ReLu$ có ưu điểm là dễ tính toán và khắc vấn đề vanishing gradient, nhược điểm của nó là nếu $f(z) = 0$ thì chúng ta không thể tính được đạo hàm cấp một tại đây (đạo hàm tại $0$ là không xác định, tức không có đạo hàm). 
  
## 1.2. The loss and cost functions in deep learning
* Mọi machine learning model đều có một ***cost function*** [hàm chi phí] (còn có những tên khác là loss function, error function) - chức năng của nó là dùng để đo model của chúng ta "hiểu" training data như thế nào.
* Dưới đây ta có một cost function $J$ như sau:
  $$J = \dfrac{1}{2m} \sum_{i = 1}^m (\widehat{y} - y)^2 \tag{1.2.1}$$

## 1.3. The forward propagation process
* **Forward propagation** là quá trình chúng ta cố gắng dự đoán **target variable** bằng cách sử dụng các **feature** của một **observation**.
* Giả sử một neural network gồm hai layer. Theo phương pháp forward propagation, chúng ta sẽ bắt đầu với các feature của observation đầu tiên $\{x_1, x_2,...,x_n\}$ và sau đó chúng ta nhân giá trị của các feature này cho các coefficient tương ứng của chúng trong layer 1, sau cùng chúng ta cộng giá trị bias vào từng neuron.
* Tiếp theo, các kết quả trên của từng neuron sẽ đi qua một activation function. Quá trình này sẽ lặp đi lặp lại cho đến cuối neural network - nơi chúng ta sẽ đữa ra kết quả dự đoạn.
* Hình dưới đây biểu diễn quá trình một neural network làm việc:
  <center>

    ![](images/01.03.png)

    _Hình 1.3.1_
  
  </center>

## 1.4. The back propagation function
* Trong tập training data, chúng ta biết được ***actual value*** [giá trị thực] của từng ***data point*** [điểm dữ liệu]. Actual value này chính là biến mà ta muốn model dự đoán, lúc này ta còn gọi nó là **target variable**, kí hiệu là $y$.
* Sau khi ta hoàn thành quá trình forward propagation, model sẽ đưa ra kết quả mà nó dự đoán cho từng data point, kí hiệu là $\widehat{y}$.
* Khi chúng ta có $y$ và $\widehat{y}$, chúng ta có thể tính được cost function. Ta có thể gọi ngắn gọn cost function là hàm $loss$.
* Để model thực sự "học" trong neural network, thì ta phải có một ***error signal*** [tín hiệu lỗi] được truyền ngược qua từng layer - bắt đầu từ layer cuối cùng đến layer đầu tiên. Error signal được dùng để cập nhật lại các weights từ đó model có thể dự đoán chính xác hơn.
* Về toán học, ta muốn tối thiểu hóa cost function càng thấp càng tốt - quá trình tối thiểu hóa cost function còn được gọi là **gradient descent**.

<hr>

* Gradient là đạo hàm riêng của error function đối với từng weight trong network. Qua từng layer, các gradient của các weight được tính. Khi các gradient được tính thì sau đó ta sử dụng quy tắc **chain rule** cùng với các gradient này để tính toán gradient descent
* Gradient descent sẽ được lặp lại và cập nhật các weight cho đến khi loss function đạt giá trị nhỏ nhất, đây la công thức cập nhật các weight theo loss function.
  $$\theta = \theta - \alpha \dfrac{\partial J}{\partial \theta} \tag{1.4.1}$$
  
  * Thuật toán gradient descent sẽ nhân các gradient $\dfrac{\partial J}{\partial \theta}$ cho ***learning rate*** [tốc độ học] - kí hiệu là $\alpha$ sau đó lấy giá trị hiện tại của các weight trừ cho tích trên.
  * Learning rate ở đây là một **hyperparameter** _(tìm hiểu sau)_.

## 1.5. Stochastic and minibatch gradient descents
_(Tìm hiểu thêm bên ngoài)_

# 2. Optimazation algorithms for deep learning
* Gradient descent thường được dùng để tối ưu hóa các weight trên neural network, tuy nhiên nó cũng là cơ sở cho nhiều thuật toán tối ưu khác ra đời. Phần tiếp theo sẽ nói sơ qua.

## 2.1. Using momentum with gradient descent
* **Gradient descent with momentum** là một biến thể của phương pháp gradient truyền thống nhằm tăng tốc độ hội tụ, công thức như sau:
  $$v_t = \beta v_{t - 1} + (1 - \beta) \times \left ( \dfrac{\partial J}{\partial \theta} \right )^2 \tag{2.1.1}$$
  $$\theta = \theta - v_t \tag{2.1.2}$$
  * Thông thường, người ta hay khởi tạo $\beta = 0.9$ và đây không phải là một hyperparameter nên cần thay đổi giá trị của $\beta$ trong quá trình học.

## 2.2. The RMSProp algorithm
* **RMSProp** cũng là một biến thể của gradient descent giúp làm tăng tốc quá trình hội tụ, công thức như sau:
  $$\theta = \theta - \alpha \dfrac{\partial J / \partial \theta}{\sqrt{v_t}} \tag{2.2.1}$$
  * Thuật toán này giúp giảm dao động ở những hướng có $v_t$ lớn.

## 2.3. The Adam optimizer
* **Adam** là một thuật toán tối ưu hóa là thuật toán tối ưu hóa tốt nhất và thường được lựa chọn đầu tiên khi giải quyết các bài toán neural network. Nó kết hợp cả hai yếu tố là momentum và RMSProp, cụ thể như sau:
  $$\text{grad} = \dfrac{\partial J}{\partial \theta} \tag{2.3.1}$$
  $$m_t = \beta_1 m_{t - 1} + (1 - \beta_1) \text{grad} \tag{2.3.2}$$
  $$v_t = \beta_2 v_{t - 1} + (1 - \beta_2) \text{grad} \tag{2.3.3}$$
  $$\theta = \theta - \alpha \dfrac{m_t}{\sqrt{v_t + \epsilon}}$$
  * Với $\epsilon$ là một giá trị cực nhỏ để tránh tình huống chia cho $0$.