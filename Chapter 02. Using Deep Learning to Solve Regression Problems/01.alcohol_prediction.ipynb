{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Using deep neural networks for regression\n",
    "## 2.1. How to plan a machine learning problem\n",
    "* Khi xây dựng một deep neural network, hãy theo dõi các bước sau:\n",
    "  * Vạch ra vấn đề ta đang muốn giải quyết.\n",
    "  * Xác định input và output của model.\n",
    "  * Xác định cost function.\n",
    "  * Tạo một network.\n",
    "  * Đào tạo và hiệu chỉnh network.\n",
    "  \n",
    "## 2.2. Defining our example problem\n",
    "* Chúng ta sẽ sử dụng dataset ***wine quality*** [chất lượng rượu] [tại đây](https://archive.ics.uci.edu/ml/datasets/wine+quality) cho các bài toán cho đến khi tôi thông báo ta sẽ sử dụng một dataset mới.\n",
    "* Có tổng số 4898 observation trong dataset này. Con số này có vẻ khá lơn với bài toán regression cổ điển nhưng lại khá nhỏ cho deep neural network.\n",
    "* Có 10 đặc điểm hóa học mà ta cần dùng để dự đoán cho target variable (`alcohol`) và chúng đều là các continous variable. Vùng blue square là independent variable và red square là dependent variable:<br>\n",
    "  ![](./images/02.00.png)\n",
    "\n",
    "## 2.3. Loading the dataset\n",
    "* Chúng ta cần load dữ liệu wine quality lên như sau:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "TRAIN_DATA = \"./data/train/train_data.csv\"\n",
    "VAL_DATA = \"./data/val/val_data.csv\"\n",
    "TEST_DATA = \"./data/test/test_data.csv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def load_data():\n",
    "    '''Load train, val and test datasets from disk.'''\n",
    "    train = pd.read_csv(TRAIN_DATA)\n",
    "    val = pd.read_csv(VAL_DATA)\n",
    "    test = pd.read_csv(TEST_DATA)\n",
    "    \n",
    "    '''Using sklearn's StandardScaler to scale our data to 0 mean and unit variance.'''\n",
    "    scaler = StandardScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    val = scaler.transform(val)\n",
    "    test = scaler.transform(test)\n",
    "    \n",
    "    '''We will use a dict to keep all this data.'''\n",
    "    data = dict()\n",
    "    data['train_y'] = train[:, 10]\n",
    "    data['train_X'] = train[:, 0:9]\n",
    "    data['val_y'] = val[:, 10]\n",
    "    data['val_X'] = val[:, 0:9]\n",
    "    data['test_y'] = test[:, 10]\n",
    "    data['test_X'] = test[:, 0:9]\n",
    "    \n",
    "    '''Keep the `scaler` so we can unscale prediction in the future.'''\n",
    "    data['scaler'] = scaler\n",
    "    \n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4. Defining our cost function\n",
    "* Đối với các bài toán hồi quy, cost function hay được dùng là **Root Mean Squared Error - RMSE** và **Mean Absolute Error - MAE**. Ở đây chúng ta sẽ dùng MAE, công thức như sau:\n",
    "  $$\\mathrm{MAE} = \\dfrac{1}{n} \\sum_{j = 1}^n |y_j - \\widehat{y_j}|$$\n",
    "\n",
    "* Bạn cũng có thể sử dụng RMSE như sau:\n",
    "  $$\\mathrm{RMSE} = \\sqrt{\\dfrac{1}{n} \\sum_{j = 1}^n (y_j - \\widehat{y_j})^2}$$\n",
    "\n",
    "* Có thể bạn sẽ bối rối ụa hai cái này làm sao biết nên chọn cái nào:\n",
    "  * Trong trường hợp lỗi phân bố đều trên training data thì $\\mathrm{RMSE} = \\mathrm{MAE}$, ví dụ ta có 10 data point và 10 data point này đều có $|y_j - \\widehat{y_j}| = 5$.\n",
    "  * Còn nếu training data có outlier thì $\\mathrm{RMSE}$ sẽ **lớn hơn rất nhiều** so với $\\mathrm{MAE}$.\n",
    "* Không có một chuẩn nào đặt ra cho việc lựa chọn cost function, chủ yếu là do cảm nhận của bạn vào dataset. Nhưng về diễn giải, $\\mathrm{MAE}$ dễ hiểu hơn so với $\\mathrm{RMSE}$.\n",
    "\n",
    "# 3. Building and MLP in Keras\n",
    "* Một model của Keras là một tập hợp của các layer và chúng ta cần định nghĩa tập các layer này cho Keras hiểu.\n",
    "* Keras hiện có hai API để đào tạo model. Trong ví dụ này, chúng ta sẽ sử dụng **Functional API** - nó khá là dài dòng về mặt coding nhưng khả năng tùy biến của nó cao. Hầu hết các pro đều sài Functional API.\n",
    "\n",
    "* Model MLP của chúng ta sẽ cần:\n",
    "  * Một input layer.\n",
    "  * Một hidden layer.\n",
    "  * Một output layer.\n",
    "\n",
    "## 3.1. Input layer shape\n",
    "* Input của chúng ta là một matrix với số dòng là số lượng observation và số cột là số lượng feature của dataset. Vậy input matrix của chúng ta có shape là $\\text{số lượng observation} \\times 10$.\n",
    "* Tuy nhiên, chúng ta không cần phải xác định chính xác shape của input matrix. TensorFlow và Keras cho phép chúng ta định nghĩa giá trị `None` cho biến **placeholder** và chúng ta hoàn toàn có thể định nghĩa lại biến placeholder này về sau.\n",
    "\n",
    "## 3.2. Hidden layer shape\n",
    "* Hidden layer của chúng ta sẽ có 32 neutron. Tại thời điểm này chúng ta không thể biết chính xác chúng ta cần bao nhiêu neutron cho network vì đây là một hyperparameter và ta cần hiệu chỉnh nó về sau. Việc xác định kiến trúc của một network là một vấn đề mở rộng trong deep learning.\n",
    "* Vì chúng ta có 32 neutron trong hidden layer, input layer của chúng ta gồm 10 feature nên shape của hidden layer là (10, 32).\n",
    "\n",
    "## 3.3. Output layer shape\n",
    "* Output layer của chúng ta sẽ bao gồm duy nhất một neuron, nó nhận vào 32 neutron của hidden layer như là input của nó và tiến hành dự đoán ra một giá trị $\\widehat{y}$ duy nhất cho từng data point.\n",
    "* Vậy model MLP của chúng ta sẽ trông thế này:<br>\n",
    "  <center>\n",
    "\n",
    "    ![](./images/02.01.png)\n",
    "\n",
    "  </center>\n",
    "  \n",
    "## 3.4. Neural network architecture\n",
    "* Bây giờ chúng ta sẽ định nghĩa input và output."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def build_network(input_features=None):\n",
    "    inputs = Input(shape=(input_features,), name='input') # input layer\n",
    "    x = Dense(32, activation='relu', name='hidden')(inputs) # hidden layer với 32 neuron\n",
    "    prediction = Dense(1, activation='linear', name='final')(x) # output layer với 1 neuron\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=prediction) # build model với input và output\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error') # biên dịch model với adam optimizer và loss mà MAE\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Hãy khám phá hàm trên:\n",
    "  * Dòng code số 4 ta dùng activation function là `linear`, điều này cũng giống như việc chúng ta không sử dụng bất kì activation function nào, đây là những gì mà chúng ta muốn cho bài toán hồi quy\n",
    "  * Dòng code số 6, ta định nghĩa đâu là input layer và đâu là output layer cho `Model` object.\n",
    "  * Dòng code số 7, ta định nghĩa Adam optimizer cho `optimizer` và MAE cho `loss` function.\n",
    "* Bây giờ chúng ta có thể gọi hàm `build_model()` để xây dựng một neural network như sau:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model = build_network(input_features=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Giả sử bây giờ ta muốn hiệu chỉnh các hyperparameter của Adam optimizer thì ta có thể làm như sau:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from keras.optimizers import adam_v2\n",
    "\n",
    "def build_network_with_adam_hyperparams(input_features=None):\n",
    "    inputs = Input(shape=(input_features,), name='input') # input layer\n",
    "    x = Dense(32, activation='relu', name='hidden')(inputs) # hidden layer với 32 neuron\n",
    "    prediction = Dense(1, activation='linear', name='final')(x) # output layer với 1 neuron\n",
    "    \n",
    "    adam_optimizer = adam_v2.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=prediction) # build model với input và output\n",
    "    model.compile(optimizer=adam_optimizer, loss='mean_absolute_error') # biên dịch model với adam optimizer và loss mà MAE\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5. Training the Keras model\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit ('python3.6': conda)"
  },
  "interpreter": {
   "hash": "2cade657992b47716e26d0a9b1443bfbca37741f9a577328e2d148cb3e78348d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}